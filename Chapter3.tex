\chapter{Methodology} 
\label{chapter:method}

\pagestyle{plain}
% Define some numbers here for the autmation of the tables
\newcommand{\libsodiumfunctions}{869}
\newcommand{\qrcodefunctions}{1849}
\newcommand{\allmewefunctions}{\libsodiumfunctions + \qrcodefunctions}

% Execute a python script for small calculations
\newcommand{\py}[1]{\input{|python3 interpreter.py #1}}
\newcommand{\fromjson}[2]{\input{| jq -r '#2' #1}}

\newcommand{\corpusrosetta}{\fromjson{data/crow_corpus.json}{.[0].name}}
\newcommand{\corpussodium}{Libsodium\xspace}
\newcommand{\corpusqrcode}{QrCode\xspace}


\newcommand{\DTWStatic}{dt\_static\xspace}
\newcommand{\DTW}{TraceDiff\xspace}
\newcommand{\tool}{CROW\xspace}

%\todo{Recheck the selection of the modules for sodium}

%This chapter investigates whether we can artificially create program variants through semantically equivalent code transformations. We propose a framework to generate program variants functionally equivalent to their original.
%We introduce the retargeting of a superoptimizer, using its exhaustive search strategy to provide semantically equivalent code transformations. 
%The presented methodology and transformation tool, CROW, are contributions to this thesis.
%We evaluate the usage of CROW on two corpora of open-source and nature diverse programs. 
In this chapter, we present our methodology to answer the research questions enunciated in \autoref{intro:definition:rq}.
We investigate three research questions. In the first question, \todo{we artificially generate \wasm program} \todo{This is the how, the why is more important} variants and quantitatively compare the static differences between variants. 
Our second research question focuses on comparing their behavior during their execution.
The final research question evaluates the feasibility of using the program variants in security-sensitive environments. We evaluate our generated program variants in an Edge-Cloud computing platform proposing a novel multivariant execution approach.

The main objective of this thesis is to study the feasibility of automatically creating program variants out of preexisting program sources. To achieve this objective,
we use \todo{too generic: the empirical method \cite{Runeson2020}}, proposing a solution and evaluating it through quantitative analyzes in case studies. We follow an iterative and incremental approach on the selection of programs for our corpora. To build our corpora, we find a representative and diverse set of programs to generalize, even when it is unrealistic following an empirical approach, as much as possible our results.
We first enunciate the corpora we share along this work to answer our research questions. Then, we establish the metrics for each research question, set the configuration for the experiments, and describe the protocol.

% Our approach lies under \textit{Design Science} \cite{Runeson2020}, in terms of empirical validation, the scope of the design knowledge gained in a study can be extended by systematically extending the scope of the valudation in subsequent studies. Thus, the size of our corpora can be extended to increase the knowledge of the research area.


\section*{Corpora}
\label{section:crow:corpora}

Our experiments assess the impact of artificially created diversity. The first step is to build a suitable corpus of programs' seeds to generate the variants. Then, we answer all our research questions with three corpora of \todo{Not explained: diverse and representative} programs for our experiments. 
We build \todo{why three: tell the reader here it feels like a magic number our three corpora} in an escalating strategy. The first corpus is diverse and contains simple programs in terms of code size, making them easy to manually analyze. The second corpus is a project meant for security-sensitive applications. The third corpus is a QR encoding decoding algorithm. The work of Hilbig \etal \cite{Hilbig2021AnES} shows that approximately 65\% of all \wasm programs come out of C/C++ source code through the LLVM pipeline, and more than 75\% if the Rust language is included. Therefore, all modules in the corpora are considered to come along the LLVM pipeline. In the following, we describe the filtering and description of each corpus.

\begin{enumerate}
    \item \textbf{\corpusrosetta}: We take programs from the  Rosetta Code project\footnote{\url{http://www.rosettacode.org/wiki/Rosetta_Code}}. This website hosts a curated set of solutions for specific programming tasks in various programming languages. It contains many tasks, from simple ones, such as adding two numbers, to complex algorithms like a compiler lexer. We first collect all C programs from the Rosetta Code, representing $989$ programs as of 01/26/2020. We then apply several filters: the programs should successfully compile and, they should not require user inputs to automatically execute them, the programs should terminate and should not result in non-deterministic results. 
    
    The result of the filtering is a corpus of 303 C programs. All programs include a single function in terms of source code. These programs range from $7$ to $150$ lines of code and solve a variety of problems, from the \textit{Babbage} problem to  \textit{Convex Hull} calculation.

    \item \textbf{\corpussodium}: This project is encryption, decryption, signature, and password hashing library implemented in 102 separated modules. The modules have between $8$ and $2703$ lines of code per function. This project is selected based on two main criteria: first, its importance for security-related applications, and second, its suitability to collect the modules in LLVM intermediate representation. %We select 5 programs that interconnect the 102 modules of the project.

    \item \textbf{\corpusqrcode}: This project is a QrCode and MicroQrCode generator written in Rust. This project contains 2 modules having between $4$ and $725$ lines of code per function. As \corpussodium, we select this project due to its suitability for collecting the modules in their LLVM representation. Besides, this project increases the complexity of the previously selected projects due to its integration with the generation of images.
    
\end{enumerate}

In \autoref{table:corpora} we listed the corpus name, the number of modules, the total number of functions, the range of lines of code, and the original location of the corpus. 


%The first corpus, \textbf{CROW prime}, . The second corpus, \textbf{MEWE prime}, is part of the MEWE contribution \cite{}. In \autoref{table:corpora} we summarize the selection criteria, and we mention each corpus properties. With both corpora we evaluate CROW with a total of $303 + \py{\allmewefunctions}$ functions. 


\todo{Add commit sha1 for libsodium and qrcode.}

\begin{table}[h]
    \renewcommand{\arraystretch}{1.0}
    \small
    \centering
    \begin{tabular}{l | l | l | l | p{3.2cm}}
        Corpus & No. modules & No. functions & LOC range & Location \\
        \midrule
            % CROW
            \corpusrosetta &
            - %\footnote{ The concept of module does not apply for this corpus programs. } 
            &
            \fromjson{data/crow_corpus.json}{.[0].functions}  & 
            \fromjson{data/crow_corpus.json}{.[0].min_lines} - 
            \fromjson{data/crow_corpus.json}{.[0].max_lines} & 
            \url{https://github.com/KTH/slumps/tree/master/benchmark_programs/rossetta/valid/no_input}\\
        \hline
        \corpussodium & 
        102 &
        \fromjson{data/allinone.multivariant.bc.massive.sodium.json}{.total_functions}  &
        \fromjson{data/allinone.multivariant.bc.massive.sodium.json}{.min_llvm_loc} - \fromjson{data/allinone.multivariant.bc.massive.sodium.json}{.max_llvm_loc}  &   
        \url{https://github.com/jedisct1/libsodium }\\
        \hline
        \corpusqrcode & 
        2 &
        \fromjson{data/allinone.multivariant.bc.massive.qr.json}{.total_functions}  & 
        \fromjson{data/allinone.multivariant.bc.massive.qr.json}{.min_llvm_loc} - \fromjson{data/allinone.multivariant.bc.massive.qr.json}{.max_llvm_loc}   & 
        \url{https://github.com/kennytm/qrcode-rust} \\
        % Total stats
        \hline
        \hline
        \textbf{Total} & 
        & 
        \py{ 303 + \qrcodefunctions + \libsodiumfunctions} &  
        &     \\

    \end{tabular}
    \caption{Corpora description. The table is composed by the name of the corpus, the number of modules, the number of functions, the lines of code range and the location of the corpus.}
    \label{table:corpora}
\end{table}

\input{method/RQ1.tex}

\input{method/RQ2.tex}

\input{method/RQ3.tex}

%\pagebreak

\section*{Conclusions}

This chapter presents the methodology we follow to answer our three research questions. We first describe and propose the corpora of programs used in this work. We propose to measure the ability of our approach to generate variants out of \py{303  + \libsodiumfunctions + \qrcodefunctions} functions of our corpora. Then, we suggest using the generated variants to study to what extent they offer different observable behavior through dynamic analysis. We propose a protocol to study the impact of the composition variants in a multivariant binary deployed at the Edge. Besides, we enumerate and enunciate the properties and metrics that might lead us to answer the impact of automatic diversification for \wasm programs. In the next chapter, we present and discuss the results obtained with this methodology.


%\todo{Add the unique and the total.}
%\todo{Change metrics and the name of dt\_dyn.}
%\todo{Remove growing factor.}
%\todo{Explain what a quantile-quantile plot is.}

\clearpage