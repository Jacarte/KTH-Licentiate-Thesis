\section{Software Diversification}
\label{sota:sota}
%Checkmarck symbol
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 

% Commands to refer to the milestones
\newtheoremstyle{sota}% name of the style to be used
  {\topsep}% measure of space to leave above the theorem. E.g.: 3pt
  {\topsep}% measure of space to leave below the theorem. E.g.: 3pt
  {\itshape}% name of font to use in the body of the theorem
  {0pt}% measure of space to indent
  {\bfseries}% name of head font
  {}% punctuation between head and body
  { }% space after theorem head; " " = normal interword space
  {(\thmname{#1}\thmnumber{#2})\textnormal{\thmnote{ (#3)}}}

\def\Gnospace~{G{}}
\theoremstyle{sota}
\newtheorem{goal}{G}
\providecommand*{\definitionautorefname}{\Gnospace}
\newcommand{\goalautorefname}{\Gnospace}


\def\Snospace~{S{}}
\theoremstyle{sota}
\newtheorem{strategy}{S}
\providecommand*{\definitionautorefname}{\Snospace}
\newcommand{\strategyautorefname}{\Snospace}

\def\Unospace~{U{}}
\theoremstyle{sota}
\newtheorem{usage}{U}
\providecommand*{\definitionautorefname}{\Unospace}
\newcommand{\usageautorefname}{\Unospace}

%\%todo{Esta muy regado ahora.}

%\todo{Stress input-output equivalence in the artificial diversification.}

%\todo{Mention concrete objective and achievement when citing.}

%\todo{emove some strategies, just cite some papers and thats it. Reduce to five transformations. Stick to U2 andd U3. Add techincal stack in the table.}

%\todo{Add level of transformation as a dimension. Hoigh level, fine-grained transofmrations, etc}

%\todo{Start with COhen, then go form high level to fine granied and from technologies to LLVM and Wasm.}


%\todo{Given a collection of pgorams, then enumerate the usages. Second approach, multiple encapsulation in one single program.}

\termidx{Software Diversification }has been widely studied in the past decades. This section discusses its state of the art.
% What is Software diversity
Software diversification consists in synthesizing, reusing, distributing, and executing different, functionally equivalent programs. 
According to the survey of Baudry and Monperrus \cite{natural_diversity}, the motivation for software diversification can be separated in five categories: reusability \cite{pohl2005software}, software testing \cite{Chen2010AdaptiveRT}, performance \cite{10.1145/2025113.2025133}, fault tolerance \cite{1659219} and security \cite{cohen1993operating}. Our work contributes to the latter two categories. In this section we discuss related works by highlighting how they generate diversification and how they use the generated diversification. 
%We finalize by comparing our contributions with the related work.

%\todo{Do not talk about complexity of replacements, stress them in the other chapters. Stress the comparison between techniques.}

%\todo{ Important things  }

%\todo{Rework hard sentences.}

%\todo{One section on semantically equivalence and checking...}

% \todo{Split sentences by ideas.}

%\subsection*{Artificial Software Diversity.}

There are two primary sources of software diversification: Natural and Artificial Diversity \cite{natural_diversity}. This work contributes to the state of the art of Artificial Diversity, which consists of artificially synthesizing software. 
% Intro to Cohen and that functional/semantic equivalence is 
We have found that the foundation for artificial software diversity has barely changed since Cohen in 1993 \cite{cohen1993operating}. Therefore, the work of Cohen is the cornerstone of this dissertation.



% Why we use their approach

\subsection*{Variants' generation}
% Mutation strategy
Cohen \etal proposed to generate artificial software diversification through mutation strategies.
A mutation strategy is a set of rules to define how a specific component of software development should be changed to provide a different yet functionally equivalent program. Cohen \etal proposed 10 concrete transformation strategies that can be applied at fine-grained level. 
All described strategies can be mixed together. They can be applied in any sequence and recursively, providing a richer diversity environment. We summarize them, complemented with the work of Baudry and Monperrus \cite{natural_diversity} and the work of Jackson \etal \cite{jackson}, in 5 strategies.

% A mutation can be applied at different layers of software lifecycle, from compilation to execution and from source code to executable binary.


%Natural diversity can be controlled or an unpredicted consequence of developing processes. Controlled natural diversity is usually called Design Diversity or N-Version Diversity. It is addressed using engineering decisions \cite{1659219}. 
%In practice, Natural Diversity consists of providing N development teams with the exact requirements. The teams develop N independent versions using different approaches. On the other hand, Natural Diversity can emerge from spontaneous software development processes. To illustrate the Natural Diversity phenomenon, CodeForces\footnote{\url{https://codeforces.com/contest/1667/status/page/2?order=BY_PROGRAM_LENGTH_ASC}} shows more than 350 different and successful solutions in C++ for a single requirements based problem in a single programming contest. 
%The software market is an expected source of natural diversity. Sengupta \etal \cite{10.5555/3091125.3091155} used this fact to reach the security goal (\autoref{goal:security}).



% Jump to the need of artificial
%Notice that Natural Diversity can rely on itself to escalate, and it is coped by the preexistence of software. This might be a limitation. For example, in the context o this work, the natural diversity for \wasm programs is nearly inexistence \cite{Hilbig2021AnES}. When natural diversity is not enough, it is innate to think that the source for diversification needs to be artificial. 

% Classification by Cohen



\begin{strategy}{Equivalent instructions replacement}
    \label{strategy:S1}
    \normalfont 
    Semantically equivalent code can replace pieces of programs. For example, it replaces the original code with equivalent arithmetic expressions or injects instructions that do not affect the computation result(garbage instructions). There are two main approaches for generating equivalent code: rewriting rules and exhaustive searching. The replacement strategies are written by hand as rewriting rules for the first one. A rewriting rule is a tuple composed of a piece of code and a semantic equivalent replacement. For example, Cleemput \etal \cite{Cleemput2012} and Homescu \etal~\cite{homescu2013profile} introduce the usage of inserting NOP instructions to generate statically different variants. In their works, the rewriting rule is defined as \texttt{instr => (nop instr)}, meaning that \texttt{nop} operation followed by the instruction is a valid replacement .
    On the other hand, exhaustive searching samples or constructs all possible programs for a specific language. In this topic, Jacob \etal \cite{jacob2008superdiversifier} proposed the technique called superdiversification for x86 binaries. Similarly, Tsoupidi \etal \cite{Tsoupidi2020ConstraintBasedSD} introduced Diversity by Construction, a constraint-based compiler to generate software diversity for MIPS32 architecture.  
     %Their technique relies in using a constraint solver to generate program variants that by construction are semantically equivalent.
    %Compared to other techniques, the works of Jacob \etal and Tsoupidi \etal do not need the writing of replacement strategies by hand, but they are limited by the reach of theorem solvers and the generation of variants can only be static. 
    %An enumerative synthesis is a brute-force approach to generate program variants. With a maximum number of instructions, it constructs and checks all possible programs up to that limit. For a simplified instance, with a maximum code size of 2 instructions in a programming language with $L$ possible constructions, an enumerative synthesizer builds and checks all $L\times L$ combinations of programs. 
    %
\end{strategy}


\begin{strategy}{Instruction reordering}
    \label{strategy:S2}
    \normalfont
    This strategy reorders instructions or entire program blocks if they are independent.
    The location of variable declarations might change as well if compilers resort them in the symbol tables. It prevents static examination and analysis of parameters and alters memory locations. In this field, Bhatkar \etal \cite{bhatkar03, bhatkar2005efficient} proposed the random permutation of the order of variables and routines for ELF binaries.
\end{strategy}

\begin{strategy}{Adding, changing, removing jumps and calls}
    \label{strategy:S3}
    \normalfont
    This strategy creates program variants by adding, changing, or removing jumps and calls in the original program. Cohen \cite{cohen1993operating} mainly illustrated the case by inserting bogus jumps in programs. Pettis and Hansen \cite{pettisochhansen} proposed to split basic blocks and functions for the PA-RISC architecture, inserting jumps between splits.
    Similarly, Crane \etal~\cite{crane2015thwarting} de-inline basic blocks of code as an LLVM pass. In their approach, each de-inlined code is transformed into semantically equivalent functions that are randomly selected at runtime to replace the original code calculation. On the same topic, Bhatkar \etal \cite{bhatkar2005efficient} extended their previous approach \cite{bhatkar03}, replacing function calls by indirect pointer calls in C source code, allowing post binary reordering of function calls. Recently, Romano \etal \cite{wobfuscator} proposed an obfuscation technique for JavaScript in which part of the code is replaced by calls to complementary \termidx{Wasm }function.
\end{strategy}


\begin{strategy}{Program memory and stack randomization}
    \label{strategy:S4}
    \normalfont
    This strategy changes the layout of programs in the host memory. Also, it can randomize how a \termidx{program variant }operates its memory. The work of Bhatkar \etal \cite{bhatkar03, bhatkar2005efficient} also proposed to randomize the base addresses of applications and the library memory regions, and the random introduction of gaps between memory objects in ELF binaries. Tadesse Aga and Autin \cite{aga2019smokestack} and Lee \etal \cite{lee2021savior} recently proposed a technique to randomize the local stack organization for function calls using a custom LLVM compiler.
    Younan \etal \cite{Younan2006} proposed to separate a conventional stack into multiple stacks where each stack contains a particular class of
    data. 
    On the same topic, Xu \etal \cite{xu2020merr} transform programs to reduce memory exposure time, improving the time needed for frequent memory address randomization. 
    %This makes it very hard for an attacker to ignore the key to inject executable code. This breaks the predictability of program execution and mitigates certain exploits. 
\end{strategy}


\begin{strategy}{ISA randomization and simulation}
    \label{strategy:S5}
    \normalfont
    This strategy encodes the original program binary. Once encoded, the program can be decoded only once at the target client, or it can be interpreted in the encoded form using a custom virtual machine implementation. This technique is strong against attacks involving the examination of code. 
    Kc \etal \cite{Kc03} and Barrantes \etal \cite{barrantes2003randomized} proposed seminal works on instruction-set randomization 
    to create a unique mapping between artificial CPU instructions and real ones.
    On the same topic, Chew and Song \cite{Chew02mitigatingbuffer} target operating system randomization. They randomize the interface between the operating system and the user applications.
    Courouss{\'e} \etal~\cite{courousse2016runtime} implement an assembly-like DSL to generate equivalent code at runtime in order to increase protection against side-channel attacks. Their technique generates a different program during execution using an interpreter for their DSL.

    %It is an interpretation mechanism similar to encoding (\autoref{strategy:S9}), but the execution of programs is delegated to a custom interpreter instead of using preexisting execution hosts. The program is decoded at runtime every time it is invoked. 
    
\end{strategy}


\begin{comment}

\begin{strategy}{Intermixing}
    \label{strategy:S10}
    \normalfont
    With the existence of more than one program variant, the execution of program variants can be mixed. The decision of which variant executes is decided at runtime. This strategy is the core for randomization, \termidx{multivariant }execution and the execution by consensus defined in \autoref{goal:reliability}. This strategy is 
    complex to implement because the integrity of the memory and stack needs to be stable between programs.
\end{strategy}
\end{comment}
 


\subsection*{Variants' equivalence}

\todo{Check}

Equivalence checking between program variants is an essential component for any program transformation task, from checking compiler optimizations \cite{LeCompilers} to the artificial synthesis of programs discussed in this chapter. 
Equivalence checking proves that two pieces of code or programs are semantically equivalent.
This process is undecidable; still, some approaches approximate it \cite{churchill2019}. % Why is important
Cohen \cite{cohen1993operating} simplifies this process by enunciating the following property: two programs equivalent if given identical input, they produce the identical output. We use this same enunciation as the definition of \emph{functional equivalence} along with this dissertation. 
Equivalence in \termidx{Software Diversification }aims to preserve the original functionality or programs while changing observable behaviors. For example, two programs can be statically different or have different execution times and provide the same computation. 



Humans, different DNA but similar as humans?
The same feeling, the same performance, but some engine room parts and their connections are to some extent different.



% The relaxation of the equivalence checking
%Notice that this property is relaxed. Two programs can be statically different but still provide the same semantic output. For example, the work of Sengupta \etal \cite{sengupta} uses the rotation of different database engines for reliability. In this case, all database engines provide the same input/output property for creating, updating, and adding new data. Their solution has input/output equivalent programs provided by statically different binaries with different observable behaviors during runtime. On the contrary, the best example of restricted equivalence checking is the one followed by most antivirus applications. In practice, most of them check for the presence of the same binary in an enormous database, \ie if two programs are exactly the same binary, they are also semantically equivalent.


% Using the test suite and equivalence by construction
The easiest way to guarantee the equivalence property is by construction. For example, in the case illustrated in \autoref{strategy:S1} for Cleemput \etal \cite{Cleemput2012} and Homescu \etal \cite{homescu2013profile}, the transformation strategy is designed to generate semantically equivalent program variants. However, this process is prone to developer errors, and more checking is needed. For example, the test suite of the original program can be used to check the variant. If the test suite passes for the \termidx{program variant }\cite{harrand2020java}, it is equivalent to the original. However, it is limited due to the need for a preexisting test suite. When the test suite does not exist, another technique is needed to check for equivalence.

% Automatic equivalence checking
The majority of the previously mentioned works use theorem solvers (SMT solvers) \cite{SMT_solver} or fuzzers \citationneeded to prove equivalence. For SMT solvers, the main idea is to turn the two code variants into mathematical expressions. The SMT solver checks for counter-examples. When the SMT solver finds a counter-example, there exists an input for which the two math expressions return a different output. The main limitation of this technique is that all algorithms cannot be translated to a math expression, for example, loops. Yet, this technique tends to be the most used for no-branching-programs checking like basic block and peephole replacements \citationneeded.
On the other hand, fuzzers look randomly for inputs that provide different observable behavior. If two inputs provide a different output in the variant, the variant and the original program are not semantically equivalent. The main limitation for fuzzers is that the process is remarkably time-expensive and requires the introduction of oracles by hand. In practice,  a fuzzer needs a significant amount of time to check two programs, and this time takes hours at the minimum. 

% Why SMT solvers
We have found that SMT solvers are the best option for checking most of the fine-grained transformations previously mentioned for two main reasons. First, the field of SMT is mature and provides battle-tested tooling \cite{SMT_solver, SMTGupta}. Second, the existing SMT tooling is configurable and flexible, making the checking of program variants feasible in terms of the SMT solver execution time. In \autoref{chapter:technical} we describe how we apply SMT solvers in our contributions for equivalence checking.
%\subsection*{Vertical Software Diversification}

%\todo{Architecture level, remark these works but not in our scope.}
%The mentioned techniques can be applied at any layer of the software lifecycle, at coarse-grained or fine-grained levels.
%At high-level, Harrand \etal  \cite{harrand2020java}, propose to merge several Java decompiler variants to provide an extended and improved meta-decompiler. On the same topic, Sengupta \etal \cite{10.5555/3091125.3091155} shift several database engines and backends for web applications. Their idea makes known CVEs to be available only in certain time window, making potential attackers to not always success. Moreover, Roi \etal \cite{10.1145/3318216.3363338} proposed to use several machine learning algorithms with the same task to tackle adversarial attackers, using a different algorithm every time the system is queried.
%These works used preexisting software diversity to provide improved systems, both for reliability and security.


%\todo{Remove}
%For fine-grained diversification, the before mentioned mutation strategies can be applied directly to the basecode at the instruction level, during the compilation of programs or directly to the generated binaries. As we previously mentioned Homescu \etal \cite{homescu2013profile}, Jackson \etal \cite{jackson, jackson2011compiler}, Jacob \etal \cite{jacob2008superdiversifier}, Crane \etal \cite{crane2015thwarting}, Aga \etal \cite{aga2019smokestack} and Tsoupidi \etal \cite{Tsoupidi2020ConstraintBasedSD} placed compilers in their diversification techniques. Similarly, Bathkar \etal \cite{bhatkar03,bhatkar2005efficient}, Chew and Song \cite{Chew02mitigatingbuffer}, El-Khalil and Keromytis \cite{ElKhalil2004}, and Cohen \cite{cohen1993operating} itself mostly proposed binary to binary transformations. 
%We have observed that fine-grained techniques are mainly motivated because they provide more robust diversification in terms of preservation. For example, to apply diversification techniques closer to the final execution avoid removing of code transformations by later optimization or compilation stages. Our contributions are fine-grained based. 

%Superdiversifier, all the others, and then finish with that we contribute to fine-grained.

\subsection*{Usages of Software Diversity}

After program variants are generated, they can be used in two main scenarios: Randomization or Multivariant Execution(MVE) \cite{jackson}. In \autoref{diagrams:sota:randomization} and \autoref{diagrams:sota:mve} we illustrate both scenarios. 



\newcommand{\rulesep}{\unskip\ \vrule\ }
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[height=3.1in]{diagrams/randomization.pdf}
        \vspace{0.5cm}
        \caption{Randomization scenario. Given a pool of program variants, one variant is deployed per host. Each deployment randomly selects which variant is assigned to each host. The same \termidx{program variant }is executed in the host at every program invocation between deployments. }        \label{diagrams:sota:randomization}

    \end{subfigure}
    \hspace{1.5mm}
    \rulesep
    \hspace{1.5mm}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[height=2.8in]{diagrams/mve.pdf}
        \caption{Multivariant Execution scenario. Given a pool of program variants, a sample of the pool is packaged in a \termidx{multivariant }binary that is deployed per. Each deployment randomly selects which \termidx{multivariant }binary is assigned to each host. A variant from the \termidx{multivariant }binary is randomly executed at runtime in the host, .}        \label{diagrams:sota:mve}

    \end{subfigure}
    \caption{\termidx{Software Diversification }usages. }
\end{figure}

% \todo{Split in what and how?}

\begin{usage}{Randomization:}
    \label{usage:randomization}
    \normalfont
    % What
    In the first scenario \autoref{diagrams:sota:randomization}, a program is selected from the collection of variants (program's variant pool), and at each deployment, it is assigned to a random client. 
    % How
    Jackson \etal \cite{jackson} call this a herd immunity scenario since vulnerable binaries can affect only part of the client's community. Chew and Song \cite{Chew02mitigatingbuffer}, Kc \etal \cite{Kc03} and Xu \etal \cite{xu2020merr} recompile the Linux Kernel to achieve this scenario. The Polyverse company \footnote{\url{https://polyverse.com/}} materialize their ideas in real life. They deliver a unique Linux distribution compilation for each of its clients by scrambling the Linux packages at the source code level. Similarly, El-Khalil and colleagues \cite{ElKhalil2004} proposed to use a custom compiler to generate different binaries out of the compilation process. 
    On the same topic, Aga and colleagues \cite{aga2019smokestack} proposed to generate program variants by randomizing its data layout in memory, making each variant to access the same memory in different ways. 
    %This strategy prevents the usage of one variant to exploit another clients. When clients run two program variants, a potential attacker must create one attack for each variant. 
    %Therefore, the attacker must spend more time and effort to get the same return on reward for an attack. 
    %in their work they demonstrated that this usage can prevent against ROP and JIT-ROP attacks \citationneeded. Similarly, 
    % Amarilli \etal~\cite{amarilli2011can} drastically increase the number of execution traces required by a side-channel attack
    %To illustrate the impact of this usage, the Polyverse company \footnote{\url{https://polyverse.com/}} is able to provide unique Linux distributions to each one of their clients. 

    
    
\end{usage}

\begin{usage}{Multivariant Execution(MVE):}
    \label{usage:mve}
    \normalfont
    % What
    In the second scenario \autoref{diagrams:sota:mve}, multiple program variants are composed in one single binary (\termidx{multivariant }binary) \cite{cox06}. Each multivariant binary is randomly deployed to a client. Once in the client, the \termidx{multivariant }binary executes its embedded program variants at runtime. 
    % How
    The execution of the embedded variants can be either in parallel to check for inconsistencies or a single program to randomize execution paths \cite{bhatkar03}. Bruschi et al. \cite{bruschi2007diversified} extended the idea of executing two variants in parallel with not-overlapping and randomized memory layouts. Simultaneously, Salamat \etal \cite{salamat2007stopping} modified a standard library that generates 32-bit Intel variants where the stack grows in the opposite direction, checking for memory inconsistencies. Notably, Davi \etal proposed Isomeron \cite{davi2015isomeron}, an approach  for execution-path randomization. Isomeron simultaneously loads the original program and a variant. While the program is running, Isomeron continuously flips a coin to decide which copy of the program should be executed next at the level of function calls. 
    %With Davi \etal approach, a potential attacker cannot predict whether the original or the variant of a program will execute.
    % Their approach prevents against memory corruption. 
    %Also, this system can be reached dynamically, like the work of Courouss{\'e} \etal, creating an MVE through code polymorphism \cite{10.1145/3281662}.  
    Neatly exploiting the limit case of executing only two variants in a \termidx{multivariant }binary has demonstrated to harden systems \cite{salamat2009orchestra, maurer2012tachyon,Kim2015, lu2018stopping, davi2015isomeron}.  Further two variants per \termidx{multivariant }binary,
    Agosta \etal~\cite{agosta2015meet} and Crane \etal~\cite{crane2015thwarting} used more than two generated programs in the \termidx{multivariant }composition, randomizing software control flow at runtime.  
    %Besides, . 
    

    %. Subsequent techniques focus on Multivariant. Execution for mitigating memory vulnerabilities \cite{lu2018stopping} and other specific security problems incl. return-oriented programming attacks \cite{volckaert2015cloning} and code injection \cite{SalamatJWWF11}. 
    
    %
\end{usage}


Both scenarios have demonstrated to harden security by tackling know vulnerabilities such as (JIT)ROP attacks \cite{jackson2011compiler} and power side-channels \cite{amarilli2011can}. Moreover, Artificial \termidx{Software Diversification }is a preemptive technique for yet unknown vulnerabilities \cite{jackson}. Our work contributes to both scenarios as a preemptive technique for hardening \wasm.

%\begin{usage}{Moving Target Defense(MTD):}
%    \label{usage:mtd}
%    \normalfont
%\autoref{usage:randomization} and \autoref{usage:mve} can be categorized as Moving Target Defense strategies. Moving Target Defense for software was first proposed as a collection of techniques that aim to improve the security of a system by constantly moving its vulnerable components \cite{MTDNationalCyberLaep, okhravi2013survey}. Usually, MTD techniques revolve around changing system inputs and configurations to reduce attack surfaces. 
%This increases uncertainty for attackers and makes their attacks more difficult. Ultimately, potential attackers cannot hit what they cannot see. 
%MTD can be implemented in different ways, including via dynamic runtime platforms \cite{10.1145/3318216.3363338}. 
%In the case of \autoref{usage:n-version}, this usage lacks of the time dimension, \ie program variants are not changed from time to time. 

%\end{usage}




\section{Statement of Novelty}
\label{sota:novelty}

We contribute to \termidx{Software Diversification }for \wasm using Artificial Diversification, for Randomization and Multivariant Execution usages (\autoref{usage:randomization}, \autoref{usage:mve}). 
In \autoref{table:sota:comparison} we listed related work on Artificial \termidx{Software Diversification }that support our work. The table is composed by the authors and the reference to their work, followed by one column for each strategy and usage ( \autoref{strategy:S1},  \autoref{strategy:S2},  \autoref{strategy:S3},  \autoref{strategy:S4},  \autoref{strategy:S5}, \autoref{usage:randomization} and \autoref{usage:mve}). The last column of the table summarize their technical contribution and the reach of their work. Each cell in the table contains a checkmark if the strategy or the usage of the work match the previously mentioned classifications. The rows are sorted by the year of the work in ascending order. The last two rows locate our contributions. 

\input{sota/sota_table.tex}

% Move to introduction
%The primary motivation for our contributions is that we see in \wasm a monoculture problem. If one environment is vulnerable, all the others are vulnerable in the same manner as the same \wasm binary is replicated. 
%Besides, the \wasm environment lacks natural diversity \cite{natural_diversity}. Compared to the work of Harrand \etal \citationneeded, in WebAssembly, one could not use preexisting and different program versions to provide diversification. On the other hand, while the number of related work for software diversity is large, only one approach has been applied to the context of \wasm. 
% Move to the table
%To the best of our knowledge, the closest diversification work on the browsers involving \wasm is the work of Romano \etal \cite{wobfuscator}. They proposed to de-inline JavaScript subexpressions and replace them with function calls to \wasm counterparts.  They empirically demonstrated that malware classifiers could be evaded with this diversification technique. 
%\wasm is a novel technology, and the adoption of defenses for it is still under development \cite{Narayan2021Swivel, johnson2021}. The current limitations on security and the lack of software diversity approaches for \wasm motivate our work.
% CROW
Our first contribution, CROW \cite{CROW} generates multiple program variants for \wasm using the LLVM pipeline.
It contributes to state of the art in artificially creating randomization for \wasm (\autoref{usage:randomization}). Because of the specificities of code execution in the browser (mentioned in \autoref{sota:wasm}), this can be considered a randomization approach. For example, since \wasm is served at each page refreshment, every time a user asks for a \wasm binary, she can be served a different variant provided by CROW. 
% Move to intro
%Besides, our contribution can be used in fuzzing campaigns \citationneeded to provide reliability. The diversification created by \termidx{CROW }can unleash hidden behaviors in compilers and interpreters. Thanks to CROW, a bug was discovered in the Lucet compiler \footnote{\url{https://www.fastly.com/blog/defense-in-depth-stopping-a-wasm-compiler-bug-before-it-became-a-problem}}.
%MEWE
%Notably, researching on MVE in a distributed setting like the Edge \citationneeded has been less researched. 
With MEWE \cite{MEWE}, our second contribution, we randomly select from several variants at runtime, creating a \termidx{multivariant }execution scheme(\autoref{usage:mve}) that randomizes the observable behaviors at each run of the \termidx{multivariant }binary. %We use the natural redundancy of Edge-Cloud computing architectures to deploy an internet-based MVE.

% Move to intro
% Only Voulimeneas \etal recently proposed a \termidx{multivariant }execution system by parallelizing the execution of the variants in different machines \cite{voulimeneas2021dmvx} for the sake of efficiency. 
% Move this to the technical part
%CROW, extrapolates the idea of superdiversification \cite{jacob2008superdiversifier} for \wasm. \termidx{CROW }works directly with LLVM IR, enabling it to generalize to more languages and CPU architectures, something not possible with the x86-specific approach of previous works.

%\termidx{CROW }focuses on the static diversification of software. However, 



