\chapter{Methodology} 
\label{chapter:method}

\pagestyle{plain}
% Define some numbers here for the autmation of the tables
\renewcommand{\tool}{CROW\xspace}

%\todo{Recheck the selection of the modules for sodium}

%This chapter investigates whether we can artificially create program variants through semantically equivalent code transformations. We propose a framework to generate program variants functionally equivalent to their original.
%We introduce the retargeting of a superoptimizer, using its exhaustive search strategy to provide semantically equivalent code transformations. 
%The presented methodology and transformation tool, CROW, are contributions to this thesis.
%We evaluate the usage of CROW on two corpora of open-source and nature diverse programs. 
In this chapter, we present our methodology to answer the research questions enunciated in \autoref{intro:definition:rq}.
We investigate three research questions. In the first question, we aim to investigate the static differences between variants. We evaluate the code properties that increase or diminish software diversification.
Our second research question focuses on comparing their behavior during their execution, complementing our first research question. The generated variants should be statically different, but also should provide different observable behaviors. 
The final research question evaluates the feasibility of using the program variants in security-sensitive environments. We evaluate our generated program variants in an edge-cloud computing platform proposing a novel multivariant execution approach.

% \todo{too generic: READ AGAIN to see how to land this
The main objective of this thesis is to study the feasibility of automatically creating program variants out of preexisting program sources. To achieve this objective,
we use the empirical method by Runeson \etal \cite{Runeson2020}, using the prototype solutions discussed in \autoref{chapter:technical} and evaluating them through quantitative analyses in case studies. We follow an iterative and incremental approach on the selection of programs for our corpora. To build our corpora, we find a representative and diverse set of programs to generalize, even when it is unrealistic following an empirical approach, as much as possible our results.
We first enunciate the corpora we share along this work to answer our research questions. Then, we establish the metrics for each research question, set the configuration for the experiments, and describe the protocol.

% Our approach lies under \textit{Design Science} \cite{Runeson2020}, in terms of empirical validation, the scope of the design knowledge gained in a study can be extended by systematically extending the scope of the valudation in subsequent studies. Thus, the size of our corpora can be extended to increase the knowledge of the research area.


\section{Corpora}
\label{section:crow:corpora}

Our experiments assess the impact of artificially created diversity. The first step is to build a suitable corpus of programs' seeds to generate the variants. Then, we answer all our research questions with three corpora which follow two main properties: 1) \emph{functionally diverse:} the selection of the programs is not biased by functionally fixed tasks, for example, the \corpusrosetta contains programs that solve from the \textit{Babbage} problem to calculate \textit{Convex Hull}; and 2) \emph{representative:} our corpora have 3021 programs that can be ported to \wasm, representing approximately 40\% of the unique Wasm binaries in the wild \cite{Hilbig2021AnES}.


We build our three corpora in an escalating strategy based on the merging of our previous publications. The first corpus is diverse and contains simple programs in terms of code size, making them easy to manually analyze. The second corpus is a project meant for security-sensitive applications. The third corpus is a QR encoding decoding algorithm. 
%The work of Hilbig \etal \cite{Hilbig2021AnES} shows that approximately 65\% of all \wasm\ programs come out of C/C++ source code through the LLVM pipeline, and more than 75\% if the Rust language is included. Therefore, all modules in the corpora are considered to come along the LLVM pipeline. 
In the following text, we describe the filtering and description of each corpus.

\begin{enumerate}
    \item \textbf{\corpusrosetta}: We take programs from the Rosetta Code project\footnote{\url{http://www.rosettacode.org/wiki/Rosetta_Code}}. This website hosts a curated set of solutions for specific programming tasks in various programming languages. It contains many tasks, from simple ones, such as adding two numbers, to complex algorithms like a compiler lexer. We first collect all C programs from the Rosetta Code, representing $989$ programs as of 01/26/2020. We then apply several filters: the programs should successfully compile and, they should not require user inputs for automatic execution, the programs should terminate and should not result in non-deterministic results. 
    
    The result of the filtering is a corpus of 303 C programs. All programs include a single function in terms of source code. These programs range from $7$ to $150$ lines of code.

    \item \textbf{\corpussodium}: This project is an encryption, decryption, signature, and password hashing library implemented in 102 separated modules. The modules have between $8$ and $2703$ lines of code per function. This project is selected based on two main criteria: first, its importance for security-related applications, and second, its suitability to collect the modules in LLVM intermediate representation. %We select 5 programs that interconnect the 102 modules of the project.

    \item \textbf{\corpusqrcode}: This project is a QrCode and MicroQrCode generator written in Rust. This project contains 2 modules having between $4$ and $725$ lines of code per function. As \corpussodium, we select this project due to its suitability for collecting the modules in their LLVM representation. This project increases the complexity of the previously selected projects due to its integration with image generation.
    
\end{enumerate}

In \autoref{table:corpora} we listed the corpus name, the language of the programs in the corpus, the number of modules, the total number of functions, the range of lines of code, and the original location of the corpus. 


%The first corpus, \textbf{CROW prime}, . The second corpus, \textbf{MEWE prime}, is part of the MEWE contribution \cite{}. In \autoref{table:corpora} we summarize the selection criteria, and we mention each corpus properties. With both corpora we evaluate CROW with a total of $303 + \pypy{\allmewefunctions}$ functions. 

\begin{table}[h]
    \renewcommand{\arraystretch}{1.0}
    \small
    \centering
    \begin{tabular}{l | p{1cm} | l | l | l | p{3.2cm}}
        Corpus & Lang. & No. modules & No. functions & LOC range & Location \\
        \midrule
            % CROW
            \corpusrosetta & C &
            -\footnote{ The concept of module does not apply for this corpus. } 
            &
            303  & 
            7 - 
            150 & 
            \url{https://github.com/KTH/slumps/tree/master/benchmark_programs/rossetta/valid/no_input}\\
        \hline
        \corpussodium & LLVM IR + Rust &
        102 &
        869  &
        8 - 2703 &   
        \url{https://github.com/jedisct1/libsodium/tree/2b5f8f2b6810121c2d9a8cc8a392e01f4d3de433 }\\
        \hline
        \corpusqrcode & LLVM IR + Rust &
        2 &
        1849  & 
        4 - 725   & 
        \url{https://github.com/kennytm/qrcode-rust/commit/faa4397ba7c5f441cb9a2b436c1e84a0d52ae942} \\
        % Total stats
        \hline
        \hline
        \textbf{Total} & & 
        & 
        \pypy{ 303 + \qrcodefunctions + \libsodiumfunctions} &  
        &     \\

    \end{tabular}
    \caption{Corpora description. The table is composed by the name of the corpus, programming language of the programs in the corpus, the number of modules, the number of functions, the lines of code range and the location of the corpus.}
    \label{table:corpora}
\end{table}

\input{method/RQ1.tex}

\input{method/RQ2.tex}

\input{method/RQ3.tex}

%\pagebreak

\section*{Conclusions}

This chapter presents the methodology we follow to answer our three research questions. We first describe and propose the corpora of programs used in this work. We propose to measure the ability of our approach to generate variants out of \pypy{303  + \libsodiumfunctions + \qrcodefunctions} functions of our corpora. Then, we suggest using the generated variants to study to what extent they offer different observable behavior through dynamic analysis. We propose a protocol to study the impact of the composition variants in a multivariant binary deployed at the Edge. Besides, we enumerate and enunciate the properties and metrics that might lead us to answer the impact of automatic diversification for \wasm\ programs. In the next chapter, we present and discuss the results obtained with this methodology.


%\todo{Add the unique and the total.}
%\todo{Change metrics and the name of dt\_dyn.}
%\todo{Remove growing factor.}
%\todo{Explain what a quantile-quantile plot is.}

\clearpage